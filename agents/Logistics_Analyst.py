from agno.agent import Agent
from agno.models.google import Gemini
from dotenv import load_dotenv
import json
import os
from typing import Dict, Any, List
from datetime import datetime
from agno.tools.tavily import TavilyTools
from agno.tools.calculator import CalculatorTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.tools.duckduckgo import DuckDuckGoTools

class LogisticCompatibilityAgent:
    def __init__(self, model_id: str = "gemini-2.0-flash-exp", enable_markdown: bool = True):
        load_dotenv()

        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.reports_dir = "temp_KB"
        os.makedirs(self.reports_dir, exist_ok=True)

        self.user_login = "codegeek03"
        self.current_time = "2025-04-19 21:17:20"

        self.agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash-exp",
        search=True,  
        grounding=False  # Disable grounding to allow tools and reasoning to work
    ),
    tools=[
        TavilyTools(
            search_depth='advanced',
            max_tokens=6000,
            include_answer=True
        ),
        DuckDuckGoTools(),
        Newspaper4kTools()
    ],
    description="You are an expert research analyst with exceptional analytical and investigative abilities.",
    instructions=[
        "Always begin by thoroughly searching for the most relevant and up-to-date information",
        "Cross-reference information between Tavily and DuckDuckGo searches for accuracy",
        "Provide well-structured, comprehensive responses with clear sections",
        "Include specific facts and details to support your answers",
        "When appropriate, organize information using bullet points or numbered lists",
        "If information seems outdated or unclear, explicitly mention this",
        "Focus on delivering accurate, concise, and actionable insights"
    ],
    reasoning=True,  # Enable reasoning 
    markdown=True,
    show_tool_calls=True
)

    async def analyze_top_logistics_materials(self, materials_data: Dict[str, Any],input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Simplified analysis focusing only on top 5 materials for logistics.
        """
        prompt = f"""
For the product '{materials_data["product_name"]}', identify the top 5 most logistically viable materials at '{input_data['packaging_location']}'
for '{input_data['units_per_shipment']}' units for shipment.
Consider only:
1. Transportation durability (shock resistance, handling stress)
2. Storage efficiency (stacking, warehouse conditions)
3. Cost effectiveness (transport and storage costs)

***NOTE: ONLY INCLUDE MATERIALS ORIGINALLY USED FOR PACKAGING PURPOSES; EXCLUDE ACCESSORIES SUCH AS LABELS, PRESERVATIVES, OR PRODUCT ADDITIVES. and DONT HALLUCINATE***
Return a simple JSON with exactly this structure:
{{
  "top_materials": [
    {{
      "material_name": "<name>",
      "logistics_score": <1-10>,
      "primary_advantage": "<single main logistics advantage>",
      "cost_consideration": "<brief cost impact>"
    }}
  ],
  "timestamp": "{self.current_time}",
  "user": "{self.user_login}"
}}

Focus on only the best material from each major category in the input data.
Keep all text fields under 50 characters.
"""

        try:
            response = await self.agent.arun(prompt)
            
            response_text = response.content.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]

            analysis = json.loads(response_text)
            
            # Save the analysis
            timestamp = self.current_time.replace(" ", "_").replace(":", "-")
            filename = f"logistics_top5_{timestamp}.json"
            filepath = os.path.join(self.reports_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2)
            
            analysis["report_path"] = filepath
            return analysis

        except Exception as e:
            error_data = {
                "error": f"Analysis failed: {str(e)}",
                "timestamp": self.current_time,
                "user": self.user_login
            }
            return error_data

    async def generate_brief_report(self, analysis: Dict[str, Any]) -> str:
        """
        Generates a simplified report focusing only on top materials.
        """
        if "error" in analysis:
            return f"Error generating report: {analysis['error']}"

        report = f"""
Logistics Compatibility Summary
============================
Analysis Date: {analysis['timestamp']}
Generated by: {analysis['user']}

Top 5 Materials for Logistics:
---------------------------
"""
        
        for material in analysis['top_materials']:
            report += f"\nâ€¢ {material['material_name']}"
            report += f"\n  Score: {material['logistics_score']}/10"
            report += f"\n  Main Advantage: {material['primary_advantage']}"
            report += f"\n  Cost Impact: {material['cost_consideration']}\n"

        return report

async def main():
    try:
        # Load the materials data
        with open('temp_KB/materials_by_criteria.json', 'r') as f:
            materials_data = json.load(f)

        agent = LogisticCompatibilityAgent()
        
        print("Analyzing logistics compatibility... This may take a few moments.")
        analysis = await agent.analyze_top_logistics_materials(materials_data)
        
        report = await agent.generate_brief_report(analysis)
        print("\nLogistics Compatibility Report:")
        print(report)
        
        print(f"\nFull report saved to: {analysis.get('report_path', 'Error: Report not saved')}")

    except Exception as e:
        print(f"Error: {str(e)}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())